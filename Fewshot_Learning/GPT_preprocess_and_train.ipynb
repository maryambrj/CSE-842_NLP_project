{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73c293f1-ebac-435c-9a7b-54500b3930db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/miniconda3/lib/python3.12/site-packages (0.28.0)\n",
      "Requirement already satisfied: requests>=2.20 in /opt/miniconda3/lib/python3.12/site-packages (from openai) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /opt/miniconda3/lib/python3.12/site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: aiohttp in /opt/miniconda3/lib/python3.12/site-packages (from openai) (3.10.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/lib/python3.12/site-packages (from requests>=2.20->openai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/lib/python3.12/site-packages (from requests>=2.20->openai) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/lib/python3.12/site-packages (from requests>=2.20->openai) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/lib/python3.12/site-packages (from requests>=2.20->openai) (2024.8.30)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/miniconda3/lib/python3.12/site-packages (from aiohttp->openai) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/miniconda3/lib/python3.12/site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/miniconda3/lib/python3.12/site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/miniconda3/lib/python3.12/site-packages (from aiohttp->openai) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/miniconda3/lib/python3.12/site-packages (from aiohttp->openai) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /opt/miniconda3/lib/python3.12/site-packages (from aiohttp->openai) (1.15.5)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/miniconda3/lib/python3.12/site-packages (from yarl<2.0,>=1.12.0->aiohttp->openai) (0.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ffa26ae8-75ed-413b-b939-b2c222318729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from collections import Counter\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "\n",
    "# to load the OPENAI api key:\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8eefca6f-87b4-44d4-a7f6-0faab6c31408",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b17aa766-e23f-4a8b-a8f5-d3db8a872716",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(data_split_path):\n",
    "    reviews_path = os.path.join(data_split_path, 'reviews')\n",
    "    parsed_pdfs_path = os.path.join(data_split_path, 'parsed_pdfs')\n",
    "    data_list = []\n",
    "\n",
    "    if not os.path.exists(reviews_path) or not os.path.exists(parsed_pdfs_path):\n",
    "        print(f\"Reviews path or parsed PDFs path does not exist.\")\n",
    "        return data_list\n",
    "\n",
    "    # Iterate over the review files\n",
    "    for review_filename in os.listdir(reviews_path):\n",
    "        if review_filename.endswith('.json'):\n",
    "            review_file_path = os.path.join(reviews_path, review_filename)\n",
    "            with open(review_file_path, 'r', encoding='utf-8') as f:\n",
    "                paper_data = json.load(f)\n",
    "\n",
    "            # The file name (without extension) corresponds to the paper ID\n",
    "            paper_id = os.path.splitext(review_filename)[0]\n",
    "            parsed_pdf_file = os.path.join(parsed_pdfs_path, f\"{paper_id}.pdf.json\")\n",
    "\n",
    "            if os.path.exists(parsed_pdf_file):\n",
    "                with open(parsed_pdf_file, 'r', encoding='utf-8') as f_pdf:\n",
    "                    parsed_pdf = json.load(f_pdf)\n",
    "                    metadata = parsed_pdf.get('metadata', {})\n",
    "                    title = metadata.get('title', 'No title')\n",
    "                    abstract_text = metadata.get('abstractText', '')\n",
    "                    sections = parsed_pdf.get('pdf_parse', {}).get('body_text', [])\n",
    "\n",
    "                    # Combine section texts\n",
    "                    section_texts = ' '.join([\n",
    "                        f\"{section.get('section', '')}: {section.get('text', '')}\"\n",
    "                        for section in sections\n",
    "                    ])\n",
    "                    full_body = f\"{title} {abstract_text} {section_texts}\".strip()\n",
    "            else:\n",
    "                # If the parsed PDF is not available, skip this paper\n",
    "                continue\n",
    "\n",
    "            # Extract reviews\n",
    "            reviews = paper_data.get('reviews', [])\n",
    "            review_texts = []\n",
    "            if isinstance(reviews, list):\n",
    "                for review in reviews:\n",
    "                    comments = review.get('comments', '').strip()\n",
    "                    if comments:\n",
    "                        review_texts.append(comments)\n",
    "\n",
    "            if review_texts:\n",
    "                data_list.append({\n",
    "                    'title': title,\n",
    "                    'abstract': abstract_text,\n",
    "                    'paper_content': full_body,\n",
    "                    'reviews': review_texts\n",
    "                })\n",
    "\n",
    "    return data_list\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7f9df38a-e228-439c-96e5-bcca4c5d4777",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(data_list, num_examples=3):\n",
    "    \"\"\"\n",
    "    Creates a few-shot prompt for GPT-3. Includes a few examples of feedback for papers.\n",
    "    \"\"\"\n",
    "    prompt = \"\"\n",
    "\n",
    "    for i, data in enumerate(data_list[:num_examples]):\n",
    "        title = data['title']\n",
    "        abstract = data['abstract']\n",
    "        paper_content = data['paper_content']\n",
    "        review = data['reviews'][0] if data['reviews'] else \"No review available.\"\n",
    "\n",
    "        # Example structure: Paper details followed by review\n",
    "        example = (\n",
    "            f\"Paper {i + 1}:\\n\"\n",
    "            f\"Title: {title}\\n\"\n",
    "            f\"Abstract: {abstract}\\n\"\n",
    "            f\"Paper Content: {paper_content[:500]}...\\n\"  # Truncate for brevity\n",
    "            f\"Feedback: {review}\\n\\n\"\n",
    "        )\n",
    "        prompt += example\n",
    "\n",
    "    # Adding new paper for GPT-3 to give feedback on\n",
    "    new_paper = data_list[num_examples]\n",
    "    prompt += (\n",
    "        f\"Paper {num_examples + 1}:\\n\"\n",
    "        f\"Title: {new_paper['title']}\\n\"\n",
    "        f\"Abstract: {new_paper['abstract']}\\n\"\n",
    "        f\"Paper Content: {new_paper['paper_content'][:500]}...\\n\"\n",
    "        f\"Feedback:\"\n",
    "    )\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dfd25b81-6cd8-44bb-b8c9-673ce4940f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred while calling the OpenAI API: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def main():\n",
    "    data_split_path = 'PeerRead/data/acl_2017/train' # usign teh acl_2017 one first..\n",
    "    data_list = extract_data(data_split_path)\n",
    "\n",
    "    if len(data_list) < 4:\n",
    "        print(\"Not enough data to create a prompt.\") # enough data \n",
    "        return\n",
    "\n",
    "    # Create the prompt\n",
    "    prompt = create_prompt(data_list, num_examples=3)\n",
    "\n",
    "    # Make the API call\n",
    "    try:\n",
    "        response = openai.Completion.create(\n",
    "            engine='gpt-3.5-turbo-instruct',  # you can also edit the engine here: https://stackoverflow.com/questions/77789886/openai-api-error-the-model-text-davinci-003-has-been-deprecated\n",
    "            prompt=prompt,\n",
    "            max_tokens=150,  \n",
    "            temperature=0.7,  \n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0\n",
    "        )\n",
    "\n",
    "        # Extract the generated feedback\n",
    "        generated_feedback = response.choices[0].text.strip()\n",
    "\n",
    "        # Print the feedback output from api call: \n",
    "        print(\"Generated Feedback:\\n\", generated_feedback)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred while calling the OpenAI API:\", e)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main() # run main func..\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
